{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ebb7132-9545-4a5f-b49d-861005739c51",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Studio ノートブックジョブ機能ハンズオン\n",
    "\n",
    "本ハンズオンは SageMaker Studio ノートブックの `Python 3 (Data Science)` カーネル、`ml.t3.medium (2 vCPU + 4 GiB)` インスタンスで検証しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae3b8e-8463-4607-967a-797a9c6fee95",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters for notebook job\n",
    "env = \"local\"\n",
    "experiment_name = \"diamond-price-prediction\"\n",
    "train_data_uri = \"\"\n",
    "unseen_data_uri = \"\"\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020713f-521b-419d-82c9-7b81c72fc918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_run_name = \"experiment-run-\" + env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632e508-c104-4e31-ac9d-331e3d2e6943",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 事前準備\n",
    "\n",
    "本ハンズオンを実施するには SageMaker の実行ロールに `sagemaker.amazonaws.com` および `events.amazon.aws.com` に対する信頼関係をセットする必要があります。\n",
    "後者は Amazon EventBridge サービスの URL です。\n",
    "ノートブックジョブを定期実行する際、裏側で EventBridge の仕組みを利用するため必要となります。\n",
    "\n",
    "以降のセルでハンズオン用の実行ロールを作成します。\n",
    "その他、セットする必要がある IAM ポリシーのリストなど、権限周りの最新情報は[公式ドキュメント](https://docs.aws.amazon.com/sagemaker/latest/dg/scheduled-notebook-policies.html)を参照してください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654d792-83f0-45d6-98d4-7a4b27e146fc",
   "metadata": {},
   "source": [
    "### ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35862b9-33d3-424b-95d3-2c2dc622fa9a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade boto3 sagemaker \"pycaret>=2,<3\" \"pyarrow>=2,<3\" awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb278e-c2c7-4d26-8a5f-54765f2e3a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pprint import pprint\n",
    "from logging import (\n",
    "    getLogger,\n",
    "    StreamHandler,\n",
    "    INFO,\n",
    ")\n",
    "# aws\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.utils import unique_name_from_base\n",
    "from sagemaker.s3 import (\n",
    "    S3Uploader,\n",
    "    S3Downloader,\n",
    ")\n",
    "import awswrangler as wr\n",
    "from sagemaker.experiments import Run\n",
    "# ml\n",
    "from pycaret.datasets import get_data\n",
    "from pycaret.regression import (\n",
    "    setup,\n",
    "    compare_models,\n",
    "    models,\n",
    "    create_model,\n",
    "    tune_model,\n",
    "    plot_model,\n",
    "    predict_model,\n",
    "    finalize_model,\n",
    "    save_model,\n",
    "    load_model,\n",
    "    pull,\n",
    ")\n",
    "from pycaret.utils import check_metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "handler = StreamHandler(sys.stdout)\n",
    "handler.setLevel(INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "iam = boto3.resource('iam')\n",
    "sts = boto3.client('sts')\n",
    "\n",
    "sagemaker_session = Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"NotebookJobExample\"\n",
    "account_id = sts.get_caller_identity().get(\"Account\")\n",
    "region = boto3.session.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a2310-acce-4a0b-92f1-8d87505957bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ハンズオン実行用の IAM ポリシーとロールの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43efe1-fdf4-46fe-8dac-d5ca10093437",
   "metadata": {},
   "source": [
    "#### IAM ポリシーの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f171ecf7-9f72-4b23-9664-376b8835905a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if env == \"local\":\n",
    "    policy_name = \"AmazonSageMakerStudioNotebookJobExamplePolicy\"\n",
    "    description = \"This policy is required to execute a hands-on notebook for SageMaker Studio Notebook Job, \" \\\n",
    "        + \"https://github.com/kmotohas/amazon-sagemaker-studio-notebook-job-example .\"\n",
    "\n",
    "    policy_document = {\n",
    "       \"Version\":\"2012-10-17\",\n",
    "       \"Statement\":[\n",
    "          {\n",
    "             \"Effect\":\"Allow\",\n",
    "             \"Action\":\"iam:PassRole\",\n",
    "             \"Resource\":\"arn:aws:iam::*:role/*\",\n",
    "             \"Condition\":{\n",
    "                \"StringLike\":{\n",
    "                   \"iam:PassedToService\":[\n",
    "                      \"sagemaker.amazonaws.com\",\n",
    "                      \"events.amazonaws.com\"\n",
    "                   ]\n",
    "                }\n",
    "             }\n",
    "          },\n",
    "          {\n",
    "             \"Effect\":\"Allow\",\n",
    "             \"Action\":[\n",
    "                \"events:TagResource\",\n",
    "                \"events:DeleteRule\",\n",
    "                \"events:PutTargets\",\n",
    "                \"events:DescribeRule\",\n",
    "                \"events:PutRule\",\n",
    "                \"events:RemoveTargets\",\n",
    "                \"events:DisableRule\",\n",
    "                \"events:EnableRule\"\n",
    "             ],\n",
    "             \"Resource\":\"*\",\n",
    "             \"Condition\":{\n",
    "                \"StringEquals\":{\n",
    "                   \"aws:ResourceTag/sagemaker:is-scheduling-notebook-job\":\"true\"\n",
    "                }\n",
    "             }\n",
    "          },\n",
    "          {\n",
    "             \"Effect\":\"Allow\",\n",
    "             \"Action\":[\n",
    "                \"s3:CreateBucket\",\n",
    "                \"s3:PutBucketVersioning\",\n",
    "                \"s3:PutEncryptionConfiguration\"\n",
    "             ],\n",
    "             \"Resource\":\"arn:aws:s3:::sagemaker-automated-execution-*\"\n",
    "          },\n",
    "          {\n",
    "             \"Effect\":\"Allow\",\n",
    "             \"Action\":[\n",
    "                \"sagemaker:ListTags\"\n",
    "             ],\n",
    "             \"Resource\":[\n",
    "                \"arn:aws:sagemaker:*:*:user-profile/*\",\n",
    "                \"arn:aws:sagemaker:*:*:space/*\",\n",
    "                \"arn:aws:sagemaker:*:*:training-job/*\",\n",
    "                \"arn:aws:sagemaker:*:*:pipeline/*\"\n",
    "             ]\n",
    "          },\n",
    "          {\n",
    "             \"Effect\":\"Allow\",\n",
    "             \"Action\":[\n",
    "                \"sagemaker:AddTags\"\n",
    "             ],\n",
    "             \"Resource\":[\n",
    "                \"arn:aws:sagemaker:*:*:training-job/*\",\n",
    "                \"arn:aws:sagemaker:*:*:pipeline/*\"\n",
    "             ]\n",
    "          },\n",
    "          {\n",
    "             \"Effect\":\"Allow\",\n",
    "             \"Action\":[\n",
    "                \"ec2:CreateNetworkInterface\",\n",
    "                \"ec2:CreateNetworkInterfacePermission\",\n",
    "                \"ec2:CreateVpcEndpoint\",\n",
    "                \"ec2:DeleteNetworkInterface\",\n",
    "                \"ec2:DeleteNetworkInterfacePermission\",\n",
    "                \"ec2:DescribeDhcpOptions\",\n",
    "                \"ec2:DescribeNetworkInterfaces\",\n",
    "                \"ec2:DescribeRouteTables\",\n",
    "                \"ec2:DescribeSecurityGroups\",\n",
    "                \"ec2:DescribeSubnets\",\n",
    "                \"ec2:DescribeVpcEndpoints\",\n",
    "                \"ec2:DescribeVpcs\",\n",
    "                \"ecr:BatchCheckLayerAvailability\",\n",
    "                \"ecr:BatchGetImage\",\n",
    "                \"ecr:GetDownloadUrlForLayer\",\n",
    "                \"ecr:GetAuthorizationToken\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:GetBucketLocation\",\n",
    "                \"s3:GetEncryptionConfiguration\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:DeleteObject\",\n",
    "                \"s3:GetObject\",\n",
    "                \"sagemaker:DescribeDomain\",\n",
    "                \"sagemaker:DescribeUserProfile\",\n",
    "                \"sagemaker:DescribeSpace\",\n",
    "                \"sagemaker:DescribeStudioLifecycleConfig\",\n",
    "                \"sagemaker:DescribeImageVersion\",\n",
    "                \"sagemaker:DescribeAppImageConfig\",\n",
    "                \"sagemaker:CreateTrainingJob\",\n",
    "                \"sagemaker:DescribeTrainingJob\",\n",
    "                \"sagemaker:StopTrainingJob\",\n",
    "                \"sagemaker:Search\",\n",
    "                \"sagemaker:CreatePipeline\",\n",
    "                \"sagemaker:DescribePipeline\",\n",
    "                \"sagemaker:DeletePipeline\",\n",
    "                \"sagemaker:StartPipelineExecution\"\n",
    "             ],\n",
    "             \"Resource\":\"*\"\n",
    "          }\n",
    "       ]\n",
    "    }\n",
    "\n",
    "    policy_arn: str = None\n",
    "\n",
    "    try:\n",
    "        policy = iam.create_policy(\n",
    "            PolicyName=policy_name,\n",
    "            Description=description,\n",
    "            PolicyDocument=json.dumps(policy_document),\n",
    "        )\n",
    "        logger.info(f\"Created policy {policy.arn}\")\n",
    "        policy_arn = policy.arn\n",
    "    except ClientError as e:\n",
    "        logger.warning(f\"Cloudn't create policy {policy_name}\")\n",
    "        if e.response[\"Error\"][\"Code\"] == \"EntityAlreadyExists\":\n",
    "            logger.warning(f\"{policy_name} already exists\")\n",
    "            policy_arn = f\"arn:aws:iam::{account_id}:policy/{policy_name}\"\n",
    "            logger.warning(policy_arn)\n",
    "        else:\n",
    "            logger.exception(e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2589fb20-270d-42e1-bfde-ceb94595d961",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### IAM ロールの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0174b073-9c05-4119-818d-631f29450d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if env == \"local\":\n",
    "    role_name = \"AmazonSageMakerStudioNotebookJobExampleRole\"\n",
    "\n",
    "    trust_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"sagemaker.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            },\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"events.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    role_arn: str = None\n",
    "\n",
    "    try:\n",
    "        role = iam.create_role(\n",
    "            RoleName=role_name,\n",
    "            Path=\"/service-role/\",\n",
    "            AssumeRolePolicyDocument=json.dumps(trust_policy)\n",
    "        )\n",
    "        logger.info(f\"Created role {role.arn}\")\n",
    "        role_arn = role.arn\n",
    "    except ClientError as e:\n",
    "        logger.warning(f\"Cloudn't create role {role_name}\")\n",
    "        if e.response[\"Error\"][\"Code\"] == \"EntityAlreadyExists\":\n",
    "            logger.warning(f\"{role_name} already exists\")\n",
    "            role_arn = f\"arn:aws:iam::{account_id}:role/service-role/{role_name}\"\n",
    "            logger.warning(role_arn)\n",
    "        else:\n",
    "            logger.exception(e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c636bcf-e918-4fa5-a6c5-00ed41ee2dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ロールにポリシーをアタッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81a0b3-1c51-4add-98dd-be879711923d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if env == \"local\":\n",
    "    try:\n",
    "        iam.Role(role_name).attach_policy(PolicyArn=policy_arn)\n",
    "        logger.info(f\"Attached policy {policy_arn} to role {role_name}\")\n",
    "    except ClientError:\n",
    "        logger.exception(f\"Couldn't attach policy {policy_arn} to role {role_name}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546b83f6-e4e7-474f-befb-d26d3bdbcd19",
   "metadata": {
    "tags": []
   },
   "source": [
    "## サンプルデータの準備\n",
    "\n",
    "ダイアモンドの価格データセットを用います。\n",
    "以降のコードは [PyCaret のビギナー向け回帰モデル開発チュートリアル](https://nbviewer.org/github/pycaret/pycaret/blob/master/tutorials/Regression%20Tutorial%20Level%20Beginner%20-%20REG101.ipynb)に沿って記述されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e02f76-5396-4dbd-8dea-10ab4527973e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if env == \"local\":\n",
    "    dataset = get_data(\"diamond\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9baefe-0950-44eb-bf3a-b1b3e4af762d",
   "metadata": {
    "tags": []
   },
   "source": [
    "サンプル数は6000、予測対象の Price を含むカラム数は8つ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe249b99-ed56-44bf-a892-2f59b077770d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if env == \"local\":\n",
    "    dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4941d9d-8cd6-4892-89f3-436ad0f533ce",
   "metadata": {},
   "source": [
    "学習用のトレーニングデータと予測用のデータに分けます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8b10d-2549-4652-8e2d-ca98708d97c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if env == \"local\":\n",
    "    train_data = dataset.sample(frac=0.9, random_state=int(random_seed))\n",
    "    unseen_data = dataset.drop(train_data.index)\n",
    "\n",
    "    train_data.reset_index(drop=True, inplace=True)\n",
    "    unseen_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Data for Modeling: {train_data.shape}\")\n",
    "    print(f\"Unseen Data For Predictions: {unseen_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f79f2-e913-4347-a2b5-1a676436a06d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Pandas DataFrame を CSV として保存します。\n",
    "ここでは S3 への CSV のエクスポートを AWS SDK for Pandas (awswrangler) を用いています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c62ede-35f6-41b6-8dcb-f0de8453e8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if env == \"local\":\n",
    "    train_data_uri = f\"s3://{bucket}/{prefix}/data/train\"\n",
    "    unseen_data_uri = f\"s3://{bucket}/{prefix}/data/unseen\"\n",
    "    wr.s3.to_csv(train_data, train_data_uri + \"/0001.csv\", index=False)\n",
    "    wr.s3.to_csv(unseen_data, unseen_data_uri + \"/0001.csv\", index=False)\n",
    "    logger.info(f\"Training data is uploaded to {train_data_uri}/0001.csv\")\n",
    "    logger.info(f\"Unseen data is uploaded to {unseen_data_uri}/0001.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cde58b-6ec0-4af8-9588-a6cbdf856f24",
   "metadata": {},
   "source": [
    "ノートブックジョブ実行のためにデータセットを S3 にアップロードします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0084f49-7c45-4fd2-96fd-32b6abe6a8f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ノートブックジョブ実行時は S3 からデータを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e729e60-fdfa-4575-9b78-bb8ac10f4383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if env == \"job\":\n",
    "    train_data = wr.s3.read_csv(train_data_uri)\n",
    "    unseen_data = wr.s3.read_csv(unseen_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b142c-ed5c-49a4-9cfb-acda3c3493b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SageMaker Experiments を用いた PyCaret の実験管理\n",
    "\n",
    "ここでは [PyCaret](https://pycaret.gitbook.io/docs/) という AutoML ツールを用いてダイヤモンド価格予測モデルを構築します。\n",
    "また、実験管理のために SageMaker Experiments というツールを用います。\n",
    "\n",
    "SageMaker Experiments はフルマネージドのサービスであって、実感管理のために追加のサーバーを管理することなく利用できます。\n",
    "SageMaker Studio の UI から管理画面を開くことができ、実験結果を閲覧したり、異なる実験間のメトリクスを比較したりできます。\n",
    "\n",
    "SageMaker Python SDK ではそれぞれの実験を `Run` として扱い、`log_parameter`、`log_parameters`、`log_metric`、`log_file`、`log_artifact` などのメソッドを用いて実験のメトリクスやパラメーター、入出力ファイル、アーティファクトを記録します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db3cfb-f8af-4172-b302-d6c25b33c839",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#from sagemaker.experiments import Run\n",
    "\n",
    "run_name = unique_name_from_base(base_run_name)\n",
    "output_path = f\"s3://{bucket}/{prefix}/{experiment_name}/{run_name}/\"\n",
    "\n",
    "with Run(\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=run_name,\n",
    ") as run:\n",
    "    # パラメーターをまとめて記録\n",
    "    run.log_parameters(\n",
    "        {\n",
    "            \"num_train_samples\": len(train_data),\n",
    "            \"num_test_samples\": len(unseen_data),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 入力ファイルを S3 にアップロードして記録\n",
    "    run.log_file(file_path=\"train_data.csv\", name=\"Train Data\", is_output=False)\n",
    "    run.log_file(file_path=\"unseen_data.csv\", name=\"Unseen Data\", is_output=False)\n",
    "    \n",
    "    # PyCaret の環境の初期化と特徴量変換パイプラインの作成\n",
    "    pycaret_experiment = setup(\n",
    "        data=train_data,\n",
    "        target=\"Price\",\n",
    "        session_id=int(random_seed),\n",
    "        silent=True,\n",
    "    )\n",
    "    \n",
    "    # 20以上のモデルをデフォルトのハイパーパラメーターで学習して比較し、最良のモデルを判別\n",
    "    logger.info(\"comparing models...\")\n",
    "    best_model = compare_models()\n",
    "    run.log_parameter(\"best_model\", best_model.__class__.__name__)\n",
    "    \n",
    "    # 事前定義済みのパラメーター空間をランダムグリッドサーチで探索してチューニング\n",
    "    logger.info(\"tuning best model...\")\n",
    "    tuned_model = tune_model(best_model)\n",
    "    \n",
    "    # テストデータとしてホールドアウトされたサンプルで性能評価\n",
    "    logger.info(\"evaluating model on test data\")\n",
    "    test_predictions = predict_model(tuned_model)  # 推論結果は返すがメトリクスは表示するだけ\n",
    "    \n",
    "    # MAE, MSE, RMSE, R2, RMSLE, MAPE といったメトリクスの計算結果のテーブルを取得\n",
    "    test_metrics = pull()  # pycaret.regression.pull() は直前に表示されたテーブルを返す\n",
    "    # テストデータに対する評価メトリクスを記録\n",
    "    for k, v in test_metrics.to_dict(\"records\")[0].items():\n",
    "        if k != \"Model\":\n",
    "            run.log_metric(name=f\"Test:{k}\", value=v)\n",
    "            \n",
    "    # 性能評価のためのプロットを作成\n",
    "    logger.info(\"generating plots...\")\n",
    "    residuals = plot_model(tuned_model, save=True)\n",
    "    prediction_error = plot_model(tuned_model, plot=\"error\", save=True)\n",
    "    feature_importance = plot_model(tuned_model, plot=\"feature\", save=True)\n",
    "    # 作成したプロットを記録\n",
    "    run.log_file(file_path=residuals, name=\"Residuals\", is_output=True)\n",
    "    run.log_file(file_path=prediction_error, name=\"Prediction Error\", is_output=True)\n",
    "    run.log_file(file_path=feature_importance, name=\"Feature Importance\", is_output=True)\n",
    "    \n",
    "    # ホールドアウトサンプルもすべて含めて学習\n",
    "    logger.info(\"finalizing model...\")\n",
    "    final_model = finalize_model(tuned_model)\n",
    "    # モデルのハイパーパラメーターを記録\n",
    "    model_parameters = final_model.get_params()\n",
    "    \n",
    "    def convert_value_types_to_log_parameters(params: dict):\n",
    "        \"\"\" log_parameters で記録できるようキャストする \"\"\"\n",
    "        for k, v in params.items():\n",
    "            if \"numpy\" in str(type(v)):\n",
    "                params[k] = v.item()\n",
    "            elif type(v) == bool or v is None:\n",
    "                params[k] = str(v)\n",
    "        return params\n",
    "    \n",
    "    model_parameters = convert_value_types_to_log_parameters(model_parameters)\n",
    "    run.log_parameters(model_parameters)\n",
    "    \n",
    "    # 学習したモデルを用いて予測対象のデータセットに対して予測を実行\n",
    "    logger.info(\"making predictions on unceen data...\")\n",
    "    predictions = predict_model(final_model, data=unseen_data)\n",
    "    predictions.to_csv(\"predictions.csv\", index=False)\n",
    "    # 予測結果の CSV を記録\n",
    "    run.log_file(file_path=\"predictions.csv\", name=\"predictions.csv\", is_output=True)\n",
    "    \n",
    "    # 学習したモデルと特徴量変換パイプラインを pickle として保存\n",
    "    logger.info(\"saving final model...\")\n",
    "    save_model(final_model, \"model\")\n",
    "    # 保存した pickle を S3 にアップロードして記録\n",
    "    run.log_file(file_path=\"model.pkl\", name=\"model.pkl\", is_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e25ed-01e5-4ccd-89da-06e8e407aa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
